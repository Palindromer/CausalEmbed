


Ідеї
1. Поєднати Top K та порогове значення. 
2. Визначити, які вузли не увійшли в жоден Top K. Проаналізувати їх. Вони можуть стати першими кандидатами на дофільтрацію.
3. Визначити, які вузли отримали дуже багато true-positive результатів. Ці вузли стають теж першими кандидати на доаналіз. Оскільки висока ймовріність, що ці вузли мають зв'язок з багатьма іншими. Але, в принципі, це мало би визначитися при аналізі тих інших вузлів.
4. Пробувати генерувати різні тлумачення+ембедінги. І робити top k на основі кількох ембедінгів.
5. Що якщо не потрапляють в Top K здебільшого лише ті вузли, які мають набагато нижчий вплив за інші чинники?
6. Максимально позбутися інструментальних та вимірювальних слів в тлумаченнях.
7. Спробувати сильніші LLM-моделі.
8. Випробувати інакші алгоритми оцінки схожості ембедінгів.
9. Погратися з температурою для ембедингів.
10. Розширювальний k: якщо при маленькому k було знайдено кілька коректних зв'язків, це може означати, що цей вузол може мати багато інших зв'язків, тому розширення k має сенс для знаходження.

Графік:
- Залежність повноти від кількості вузлів при ReductionRate = 10%.
- Залежність Recall від % top K.  Зробити для всіх графів. Лінія ReductionRate буде для всіх однакова (насправді не зовсім).





Нотатки
- Слід порівнювати з рандомним алгоритмом.
- Проблема анонімізованих датасетів. Датасет PIGS складається з анонімізованого ідентифікатора тварин. Тому не вдасться їх перетворити на ембедінги. Аналогічна проблема з pathfinder, ANDES.
